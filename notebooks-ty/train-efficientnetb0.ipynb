{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "경로 변경하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/taeyoonkim/kaggle-hms'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "PATH = os.getcwd()\n",
    "if not str(os.getcwd()).endswith('kaggle-hms'):\n",
    "    os.chdir(Path(PATH).parent)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.configuration import config, paths\n",
    "from src.utils import *\n",
    "from src.customdataset import CustomDataset\n",
    "from src.custommodel import CustomModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 GPU(s)\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Using', torch.cuda.device_count(), 'GPU(s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_preds = [x + \"_pred\" for x in ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']]\n",
    "label_to_num = {'Seizure': 0, 'LPD': 1, 'GPD': 2, 'LRDA': 3, 'GRDA': 4, 'Other':5}\n",
    "num_to_label = {v: k for k, v in label_to_num.items()}\n",
    "LOGGER = get_logger()\n",
    "seed_everything(config.SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 불러오기  \n",
    "원본 train data와 수정된 train data  불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataframe shape is: (106800, 15)\n",
      "Labels: ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>eeg_sub_id</th>\n",
       "      <th>eeg_label_offset_seconds</th>\n",
       "      <th>spectrogram_id</th>\n",
       "      <th>spectrogram_sub_id</th>\n",
       "      <th>spectrogram_label_offset_seconds</th>\n",
       "      <th>label_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>expert_consensus</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1628180742</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353733</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127492639</td>\n",
       "      <td>42516</td>\n",
       "      <td>Seizure</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1628180742</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>353733</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3887563113</td>\n",
       "      <td>42516</td>\n",
       "      <td>Seizure</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1628180742</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>353733</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1142670488</td>\n",
       "      <td>42516</td>\n",
       "      <td>Seizure</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1628180742</td>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>353733</td>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2718991173</td>\n",
       "      <td>42516</td>\n",
       "      <td>Seizure</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1628180742</td>\n",
       "      <td>4</td>\n",
       "      <td>24.0</td>\n",
       "      <td>353733</td>\n",
       "      <td>4</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3080632009</td>\n",
       "      <td>42516</td>\n",
       "      <td>Seizure</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eeg_id  eeg_sub_id  eeg_label_offset_seconds  spectrogram_id  \\\n",
       "0  1628180742           0                       0.0          353733   \n",
       "1  1628180742           1                       6.0          353733   \n",
       "2  1628180742           2                       8.0          353733   \n",
       "3  1628180742           3                      18.0          353733   \n",
       "4  1628180742           4                      24.0          353733   \n",
       "\n",
       "   spectrogram_sub_id  spectrogram_label_offset_seconds    label_id  \\\n",
       "0                   0                               0.0   127492639   \n",
       "1                   1                               6.0  3887563113   \n",
       "2                   2                               8.0  1142670488   \n",
       "3                   3                              18.0  2718991173   \n",
       "4                   4                              24.0  3080632009   \n",
       "\n",
       "   patient_id expert_consensus  seizure_vote  lpd_vote  gpd_vote  lrda_vote  \\\n",
       "0       42516          Seizure             3         0         0          0   \n",
       "1       42516          Seizure             3         0         0          0   \n",
       "2       42516          Seizure             3         0         0          0   \n",
       "3       42516          Seizure             3         0         0          0   \n",
       "4       42516          Seizure             3         0         0          0   \n",
       "\n",
       "   grda_vote  other_vote  \n",
       "0          0           0  \n",
       "1          0           0  \n",
       "2          0           0  \n",
       "3          0           0  \n",
       "4          0           0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(paths.TRAIN_CSV)\n",
    "label_cols = df.columns[-6:]\n",
    "print(f\"Train dataframe shape is: {df.shape}\")\n",
    "print(f\"Labels: {list(label_cols)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18013, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>eeg_min</th>\n",
       "      <th>eeg_max</th>\n",
       "      <th>spectogram_id</th>\n",
       "      <th>spec_min</th>\n",
       "      <th>spec_max</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Other</td>\n",
       "      <td>568657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>789577333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20654</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>568657Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LPD</td>\n",
       "      <td>582999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1552638400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>20230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>582999LPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Other</td>\n",
       "      <td>642382</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>14960202</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>5955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>642382Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GPD</td>\n",
       "      <td>751790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>618728447</td>\n",
       "      <td>908.0</td>\n",
       "      <td>908.0</td>\n",
       "      <td>38549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>751790GPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Other</td>\n",
       "      <td>778705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52296320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>778705Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target  eeg_id  eeg_min  eeg_max  spectogram_id  spec_min  spec_max  \\\n",
       "0  Other  568657      0.0     16.0      789577333       0.0      16.0   \n",
       "1    LPD  582999      0.0     38.0     1552638400       0.0      38.0   \n",
       "2  Other  642382      0.0     24.0       14960202    1008.0    1032.0   \n",
       "3    GPD  751790      0.0      0.0      618728447     908.0     908.0   \n",
       "4  Other  778705      0.0      0.0       52296320       0.0       0.0   \n",
       "\n",
       "   patient_id  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  \\\n",
       "0       20654           0.0  0.000000      0.25   0.000000   0.166667   \n",
       "1       20230           0.0  0.857143      0.00   0.071429   0.000000   \n",
       "2        5955           0.0  0.000000      0.00   0.000000   0.000000   \n",
       "3       38549           0.0  0.000000      1.00   0.000000   0.000000   \n",
       "4       40955           0.0  0.000000      0.00   0.000000   0.000000   \n",
       "\n",
       "   other_vote          key  \n",
       "0    0.583333  568657Other  \n",
       "1    0.071429    582999LPD  \n",
       "2    1.000000  642382Other  \n",
       "3    0.000000    751790GPD  \n",
       "4    1.000000  778705Other  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('~/kaggle-hms/data/processed/train-processed-addkey.csv')\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "캐글 스펙트로그램 읽어오기 (대용량)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11138 spectrogram parquets\n"
     ]
    }
   ],
   "source": [
    "# raw 폴더 내 spectrogram 파일의 개수만 출력\n",
    "paths_spectograms = glob(paths.TRAIN_SPECTOGRAMS + \"*.parquet\")\n",
    "print(f'There are {len(paths_spectograms)} spectrogram parquets')\n",
    "\n",
    "# 대용량 캐글 스펙트로그램 불러오기\n",
    "all_spectrograms = np.load(paths.PRE_LOADED_SPECTOGRAMS, allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EEG 스펙트로그램 불러오기 (미리 만들어두기!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 EEG spectograms\n"
     ]
    }
   ],
   "source": [
    "# raw 폴더 내 EEG 파일 개수만 출력\n",
    "paths_eegs = glob(paths.TRAIN_EEGS + \"*.parquet\")\n",
    "print(f'There are {len(paths_eegs)} EEG spectograms')\n",
    "\n",
    "# 대용량 EEG 스펙트로그램 불러오기\n",
    "all_eegs = np.load(paths.PRE_LOADED_EEGS, allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-겹 교차 검증 시행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold\n",
       "0.0    3603\n",
       "1.0    3603\n",
       "2.0    3603\n",
       "3.0    3602\n",
       "4.0    3602\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>eeg_min</th>\n",
       "      <th>eeg_max</th>\n",
       "      <th>spectogram_id</th>\n",
       "      <th>spec_min</th>\n",
       "      <th>spec_max</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "      <th>key</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Other</td>\n",
       "      <td>568657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>789577333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20654</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>568657Other</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LPD</td>\n",
       "      <td>582999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1552638400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>20230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>582999LPD</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Other</td>\n",
       "      <td>642382</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>14960202</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>5955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>642382Other</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GPD</td>\n",
       "      <td>751790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>618728447</td>\n",
       "      <td>908.0</td>\n",
       "      <td>908.0</td>\n",
       "      <td>38549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>751790GPD</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Other</td>\n",
       "      <td>778705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52296320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>778705Other</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target  eeg_id  eeg_min  eeg_max  spectogram_id  spec_min  spec_max  \\\n",
       "0  Other  568657      0.0     16.0      789577333       0.0      16.0   \n",
       "1    LPD  582999      0.0     38.0     1552638400       0.0      38.0   \n",
       "2  Other  642382      0.0     24.0       14960202    1008.0    1032.0   \n",
       "3    GPD  751790      0.0      0.0      618728447     908.0     908.0   \n",
       "4  Other  778705      0.0      0.0       52296320       0.0       0.0   \n",
       "\n",
       "   patient_id  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  \\\n",
       "0       20654           0.0  0.000000      0.25   0.000000   0.166667   \n",
       "1       20230           0.0  0.857143      0.00   0.071429   0.000000   \n",
       "2        5955           0.0  0.000000      0.00   0.000000   0.000000   \n",
       "3       38549           0.0  0.000000      1.00   0.000000   0.000000   \n",
       "4       40955           0.0  0.000000      0.00   0.000000   0.000000   \n",
       "\n",
       "   other_vote          key  fold  \n",
       "0    0.583333  568657Other   2.0  \n",
       "1    0.071429    582999LPD   1.0  \n",
       "2    1.000000  642382Other   4.0  \n",
       "3    0.000000    751790GPD   4.0  \n",
       "4    1.000000  778705Other   3.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gkf = GroupKFold(n_splits=config.FOLDS)\n",
    "for fold, (train_index, valid_index) in enumerate(gkf.split(train_df, train_df.target, train_df.patient_id)):\n",
    "    train_df.loc[valid_index, \"fold\"] = int(fold)\n",
    "    \n",
    "display(train_df.groupby('fold').size()), sep()\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터로더 DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_df, config, all_spectrograms, all_eegs, mode=\"train\")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.BATCH_SIZE_TRAIN,\n",
    "    shuffle=False,\n",
    "    num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=True\n",
    ")\n",
    "X, y = train_dataset[0]\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스케쥴러 Scheduler  \n",
    "4 epochs로 훈련하기  \n",
    "epochs 1, 2는 LR=1e-3  \n",
    "epochs 3, 4는 LR=1e-4 and 1e-5  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = config.EPOCHS\n",
    "BATCHES = len(train_loader)\n",
    "steps = []\n",
    "lrs = []\n",
    "optim_lrs = []\n",
    "model = CustomModel(config)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "scheduler = OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=1e-3,\n",
    "    epochs=config.EPOCHS,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    pct_start=0.05,\n",
    "    anneal_strategy=\"cos\",\n",
    "    final_div_factor=100,\n",
    ")\n",
    "for epoch in range(EPOCHS):\n",
    "    for batch in range(BATCHES):\n",
    "        scheduler.step()\n",
    "        lrs.append(scheduler.get_last_lr()[0])\n",
    "        steps.append(epoch * BATCHES + batch)\n",
    "\n",
    "max_lr = max(lrs)\n",
    "min_lr = min(lrs)\n",
    "print(f\"Maximum LR: {max_lr} | Minimum LR: {min_lr}\")\n",
    "plt.figure()\n",
    "plt.plot(steps, lrs, label='OneCycle')\n",
    "plt.ticklabel_format(axis='y', style='sci', scilimits=(0,0))\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "손실함수 Loss Function\n",
    "\n",
    "PyTorch의 `KLDivLoss`에서 the reduction parameter 는 서로 다른 차원에서 loss가 어떻게 집계되는지를 결정합니다. 여기서 가장 일반적인 옵션은 `mean`과 `batchmean`입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Reduction = \"mean\" ===\n",
    "criterion = nn.KLDivLoss(reduction=\"mean\")\n",
    "y_pred = F.log_softmax(torch.randn(6, 2, requires_grad=True), dim=1)\n",
    "y_true = F.softmax(torch.rand(6, 2), dim=1)\n",
    "print(f\"Predictions: {y_pred}\")\n",
    "print(f\"Targets: {y_true}\")\n",
    "output = criterion(y_pred, y_true)\n",
    "print(f\"Output: {output}\")\n",
    "\n",
    "print(\"\\n\", \"=\"*100, \"\\n\")\n",
    "\n",
    "# === Reduction = \"batchmean\" ===\n",
    "criterion = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "y_pred = F.log_softmax(torch.randn(2, 6, requires_grad=True), dim=1)\n",
    "y_true = F.softmax(torch.rand(2, 6), dim=1)\n",
    "print(f\"Predictions: {y_pred}\")\n",
    "print(f\"Targets: {y_true}\")\n",
    "output = criterion(y_pred, y_true)\n",
    "print(f\"Output: {output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 함수(train_epoch)와 검증 함수(valid_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    \"\"\"One epoch training pass.\"\"\"\n",
    "    model.train() \n",
    "    criterion = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=config.AMP)\n",
    "    losses = AverageMeter()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    \n",
    "    # ========== ITERATE OVER TRAIN BATCHES ============\n",
    "    with tqdm(train_loader, unit=\"train_batch\", desc='Train') as tqdm_train_loader:\n",
    "        for step, (X, y) in enumerate(tqdm_train_loader):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            batch_size = y.size(0)\n",
    "            with torch.cuda.amp.autocast(enabled=config.AMP):\n",
    "                y_preds = model(X) \n",
    "                loss = criterion(F.log_softmax(y_preds, dim=1), y)\n",
    "            if config.GRADIENT_ACCUMULATION_STEPS > 1:\n",
    "                loss = loss / config.GRADIENT_ACCUMULATION_STEPS\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            scaler.scale(loss).backward()\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.MAX_GRAD_NORM)\n",
    "\n",
    "            if (step + 1) % config.GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                global_step += 1\n",
    "                scheduler.step()\n",
    "            end = time.time()\n",
    "\n",
    "            # ========== LOG INFO ==========\n",
    "            if step % config.PRINT_FREQ == 0 or step == (len(train_loader)-1):\n",
    "                print('Epoch: [{0}][{1}/{2}] '\n",
    "                      'Elapsed {remain:s} '\n",
    "                      'Loss: {loss.avg:.4f} '\n",
    "                      'Grad: {grad_norm:.4f}  '\n",
    "                      'LR: {lr:.8f}  '\n",
    "                      .format(epoch+1, step, len(train_loader), \n",
    "                              remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                              loss=losses,\n",
    "                              grad_norm=grad_norm,\n",
    "                              lr=scheduler.get_last_lr()[0]))\n",
    "\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def valid_epoch(valid_loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    losses = AverageMeter()\n",
    "    prediction_dict = {}\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    with tqdm(valid_loader, unit=\"valid_batch\", desc='Validation') as tqdm_valid_loader:\n",
    "        for step, (X, y) in enumerate(tqdm_valid_loader):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            batch_size = y.size(0)\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(X)\n",
    "                loss = criterion(F.log_softmax(y_preds, dim=1), y)\n",
    "            if config.GRADIENT_ACCUMULATION_STEPS > 1:\n",
    "                loss = loss / config.GRADIENT_ACCUMULATION_STEPS\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            y_preds = softmax(y_preds)\n",
    "            preds.append(y_preds.to('cpu').numpy())\n",
    "            end = time.time()\n",
    "\n",
    "            # ========== LOG INFO ==========\n",
    "            if step % config.PRINT_FREQ == 0 or step == (len(valid_loader)-1):\n",
    "                print('EVAL: [{0}/{1}] '\n",
    "                      'Elapsed {remain:s} '\n",
    "                      'Loss: {loss.avg:.4f} '\n",
    "                      .format(step, len(valid_loader),\n",
    "                              remain=timeSince(start, float(step+1)/len(valid_loader)),\n",
    "                              loss=losses))\n",
    "                \n",
    "    prediction_dict[\"predictions\"] = np.concatenate(preds)\n",
    "    return losses.avg, prediction_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(df, fold):\n",
    "    \n",
    "    LOGGER.info(f\"========== Fold: {fold} training ==========\")\n",
    "\n",
    "    # ======== SPLIT ==========\n",
    "    train_folds = df[df['fold'] != fold].reset_index(drop=True)\n",
    "    valid_folds = df[df['fold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    # ======== DATASETS ==========\n",
    "    train_dataset = CustomDataset(train_folds, config, mode=\"train\", augment=True)\n",
    "    valid_dataset = CustomDataset(valid_folds, config, mode=\"train\", augment=False)\n",
    "    \n",
    "    # ======== DATALOADERS ==========\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=config.BATCH_SIZE_TRAIN,\n",
    "                              shuffle=False,\n",
    "                              num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset,\n",
    "                              batch_size=config.BATCH_SIZE_VALID,\n",
    "                              shuffle=False,\n",
    "                              num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=False)\n",
    "    \n",
    "    # ======== MODEL ==========\n",
    "    model = CustomModel(config)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.1, weight_decay=config.WEIGHT_DECAY)\n",
    "    scheduler = OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=1e-3,\n",
    "        epochs=config.EPOCHS,\n",
    "        steps_per_epoch=len(train_loader),\n",
    "        pct_start=0.1,\n",
    "        anneal_strategy=\"cos\",\n",
    "        final_div_factor=100,\n",
    "    )\n",
    "\n",
    "    # ======= LOSS ==========\n",
    "    criterion = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "    \n",
    "    best_loss = np.inf\n",
    "    # ====== ITERATE EPOCHS ========\n",
    "    for epoch in range(config.EPOCHS):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # ======= TRAIN ==========\n",
    "        avg_train_loss = train_epoch(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "\n",
    "        # ======= EVALUATION ==========\n",
    "        avg_val_loss, prediction_dict = valid_epoch(valid_loader, model, criterion, device)\n",
    "        predictions = prediction_dict[\"predictions\"]\n",
    "        \n",
    "        # ======= SCORING ==========\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_train_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        \n",
    "        if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n",
    "            torch.save({'model': model.state_dict(),\n",
    "                        'predictions': predictions},\n",
    "                        paths.OUTPUT_DIR + f\"/{config.MODEL.replace('/', '_')}_fold_{fold}_best.pth\")\n",
    "\n",
    "    predictions = torch.load(paths.OUTPUT_DIR + f\"/{config.MODEL.replace('/', '_')}_fold_{fold}_best.pth\", \n",
    "                             map_location=torch.device('cpu'))['predictions']\n",
    "    valid_folds[target_preds] = predictions\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return valid_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Full Data 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop_full_data(df):\n",
    "    train_dataset = CustomDataset(df, config, mode=\"train\", augment=True)\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=config.BATCH_SIZE_TRAIN,\n",
    "                              shuffle=False,\n",
    "                              num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=True)\n",
    "    model = CustomModel(config)\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.1, weight_decay=config.WEIGHT_DECAY)\n",
    "    scheduler = OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=1e-3,\n",
    "        epochs=config.EPOCHS,\n",
    "        steps_per_epoch=len(train_loader),\n",
    "        pct_start=0.1,\n",
    "        anneal_strategy=\"cos\",\n",
    "        final_div_factor=100,\n",
    "    )\n",
    "    criterion = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "    best_loss = np.inf\n",
    "    for epoch in range(config.EPOCHS):\n",
    "        start_time = time.time()\n",
    "        avg_train_loss = train_epoch(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "        elapsed = time.time() - start_time\n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_train_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        torch.save(\n",
    "            {'model': model.state_dict()},\n",
    "            paths.OUTPUT_DIR + f\"/{config.MODEL.replace('/', '_')}_epoch_{epoch}.pth\")\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    return _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 시작!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(oof_df):\n",
    "    kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "    labels = torch.tensor(oof_df[label_cols].values)\n",
    "    preds = torch.tensor(oof_df[target_preds].values)\n",
    "    preds = F.log_softmax(preds, dim=1)\n",
    "    result = kl_loss(preds, labels)\n",
    "    return result\n",
    "\n",
    "if not config.TRAIN_FULL_DATA:\n",
    "    oof_df = pd.DataFrame()\n",
    "    for fold in range(config.FOLDS):\n",
    "        if fold in [0, 1, 2, 3, 4]:\n",
    "            _oof_df = train_loop(train_df, fold)\n",
    "            oof_df = pd.concat([oof_df, _oof_df])\n",
    "            LOGGER.info(f\"========== Fold {fold} result: {get_result(_oof_df)} ==========\")\n",
    "            print(f\"========== Fold {fold} result: {get_result(_oof_df)} ==========\")\n",
    "    oof_df = oof_df.reset_index(drop=True)\n",
    "    LOGGER.info(f\"========== CV: {get_result(oof_df)} ==========\")\n",
    "    oof_df.to_csv(paths.OUTPUT_DIR + '/oof_df.csv', index=False)\n",
    "else:\n",
    "    train_loop_full_data(train_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle-hms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
